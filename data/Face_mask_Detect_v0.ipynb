{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face mask Detect_v0",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obengdouglas/DSI-2022/blob/main/Face_mask_Detect_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# <center>[The twist Challenge - DSI 2022 Module 1B](http://dsi-program.com/)\n",
        "> <center>Train and deploy a computer vision model</center>\n",
        "\n",
        "<center><img src=\"https://venturebeat.com/wp-content/uploads/2017/01/computer-vision.jpg?fit=750%2C469&strip=all\" ></center>\n",
        "\n",
        "<center><h1>Report: Douglas Obeng</h1></center>\n",
        "\n",
        "<h1>Introduction</h1>\n",
        "    \n",
        "üê†Goals of the Twist Challenge\n",
        "\n",
        "- Build a machine vision app to solve some ‚Äúinteresting‚Äù problem* \n",
        "- Get your own training data by scraping it from the web or using an API \n",
        "- You are encouraged to use pretrained vision models and fine-tune them (transfer learning) to better solve your problem\n",
        "- Build a GUI that can demo your classifier in real time on new images\n",
        "\n",
        "üê† Presentation should do the following\n",
        "\n",
        "- Explain the problem you are solving and why you chose it (NB: 80/20 rule)\n",
        "- Explain how you solved it (what model, what data, how you got your data and implemented the GUI etc‚Ä¶)\n",
        "- Do a Live demo of your tool working \n",
        "\n"
      ],
      "metadata": {
        "id": "64-PB74-EEPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CZOhHjrWEtRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrape data From the web\n",
        "- Using BeautifulSoup"
      ],
      "metadata": {
        "id": "TlYu6faAEtVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "# from urllib.request import urlopen, urlretrieve, quote\n",
        "# from urllib.parse import urljoin\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "import requests, os, string\n",
        "\n",
        "url = 'https://makeml.app/datasets/mask'\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "\n",
        "soup = bs4.BeautifulSoup(html, features=\"lxml\")\n",
        "a = soup.find('a')\n",
        "onclick = a.attrs['onclick']\n",
        "left = onclick.find(\"open('\")\n",
        "right = onclick.find(\".zip?\",left+1)\n",
        "print('URL is: {}'.format(onclick[left+6:right+4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pOPORCi_unA",
        "outputId": "52b6b6ec-6d14-4805-bb11-998b69ed45c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL is: https://arcraftimages.s3-accelerate.amazonaws.com/Datasets/Mask/MaskPascalVOC.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow link in above result to download data"
      ],
      "metadata": {
        "id": "Ans1BUTHa11T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive"
      ],
      "metadata": {
        "id": "ULxZtelRIMeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f2qjY64as-pT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6684beaf-4f15-476d-cdb0-a39ab9bdcaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "MbeZfFi2bAGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import ast\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Data/face-mask-detection')\n",
        "import torch\n",
        "from PIL import Image\n",
        "from joblib import Parallel, delayed\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "_uGQxJK6tGAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a ref=ultralytics\"><img width=\"1000\" src=\"https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png\"/></a></p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b521a429-7a8a-4399-93b8-9e9dddc8f5a2"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "from yolov5 import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v6.0-248-gcb2ad9f torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 42.2/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fLAV42oNb7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc3d822-1736-46b0-ab48-6a2132d4df57"
      },
      "source": [
        "# Weights & Biases  (optional)\n",
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mobengdouglas\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697e1f40-262f-48c4-8ade-febeee946d6a"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 8 --epochs 16 --data /content/drive/MyDrive/Colab_Data/face-mask-detection/custom_facemask.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mobengdouglas\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/Colab_Data/face-mask-detection/custom_facemask.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=16, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v6.0-248-gcb2ad9f torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-terrain-8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/obengdouglas/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/obengdouglas/YOLOv5/runs/32t1fl0i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20220211_061754-32t1fl0i\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.0M/14.0M [00:00<00:00, 115MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/Colab_Data/face-mask-detection/labels/train.cache' images and labels... 551 found, 0 missing, 0 empty, 0 corrupt: 100% 551/551 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.7GB ram): 100% 551/551 [00:10<00:00, 50.51it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/Colab_Data/face-mask-detection/labels/val.cache' images and labels... 213 found, 0 missing, 0 empty, 0 corrupt: 100% 213/213 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 213/213 [00:05<00:00, 35.82it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.59 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 16 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/15     1.73G    0.1113   0.04746   0.03838        74       640: 100% 69/69 [00:48<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:11<00:00,  1.23it/s]\n",
            "                 all        213       1226    0.00836     0.0186    0.00294   0.000583\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/15     1.97G   0.08982   0.05812   0.02784        55       640: 100% 69/69 [00:45<00:00,  1.53it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:11<00:00,  1.27it/s]\n",
            "                 all        213       1226      0.458     0.0806      0.066     0.0163\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/15     1.97G   0.07231   0.04823    0.0222        41       640: 100% 69/69 [00:45<00:00,  1.53it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "                 all        213       1226      0.832      0.135      0.134     0.0473\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/15     1.97G   0.06764   0.04106   0.01911        22       640: 100% 69/69 [00:44<00:00,  1.53it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.57it/s]\n",
            "                 all        213       1226      0.796      0.186      0.117     0.0284\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/15     1.97G   0.06368   0.03879   0.01814        34       640: 100% 69/69 [00:44<00:00,  1.54it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.61it/s]\n",
            "                 all        213       1226      0.835      0.184       0.17     0.0532\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/15     1.97G   0.06182    0.0381    0.0181        42       640: 100% 69/69 [00:44<00:00,  1.54it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.62it/s]\n",
            "                 all        213       1226      0.834      0.203      0.181     0.0519\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/15     1.97G   0.05947   0.03477   0.01679        29       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.64it/s]\n",
            "                 all        213       1226      0.513      0.326      0.209     0.0614\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/15     1.97G   0.05787   0.03347   0.01484        40       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.61it/s]\n",
            "                 all        213       1226      0.529      0.429      0.273      0.091\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/15     1.97G   0.05427   0.03237   0.01287        57       640: 100% 69/69 [00:44<00:00,  1.54it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.60it/s]\n",
            "                 all        213       1226      0.684      0.423      0.392      0.158\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/15     1.97G   0.05301   0.03071   0.01181        23       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.62it/s]\n",
            "                 all        213       1226      0.692      0.397      0.366       0.14\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/15     1.97G   0.04945   0.03011   0.01055        44       640: 100% 69/69 [00:44<00:00,  1.54it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.61it/s]\n",
            "                 all        213       1226      0.721      0.426      0.417      0.192\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/15     1.97G   0.04734   0.03181   0.00977        37       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.65it/s]\n",
            "                 all        213       1226      0.808      0.433      0.461      0.218\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/15     1.97G   0.04282   0.03035   0.00962        33       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.68it/s]\n",
            "                 all        213       1226      0.772      0.452      0.457      0.231\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/15     1.97G   0.04181   0.02923  0.008684        49       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.69it/s]\n",
            "                 all        213       1226      0.891      0.439      0.494      0.237\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/15     1.97G    0.0404   0.02928  0.008434        61       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.69it/s]\n",
            "                 all        213       1226      0.881      0.474      0.521      0.265\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/15     1.97G   0.03576   0.02583  0.007756        45       640: 100% 69/69 [00:44<00:00,  1.55it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:08<00:00,  1.70it/s]\n",
            "                 all        213       1226      0.901       0.47      0.541      0.305\n",
            "\n",
            "16 epochs completed in 0.249 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 14/14 [00:13<00:00,  1.04it/s]\n",
            "                 all        213       1226      0.902       0.47      0.541      0.305\n",
            "mask weared incorrect        213         35          1          0     0.0627     0.0397\n",
            "           with mask        213       1021      0.913      0.823       0.89      0.519\n",
            "        without mask        213        170      0.793      0.588      0.672      0.356\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 653... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             best/epoch 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/mAP_0.5 0.54138\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      best/mAP_0.5:0.95 0.30508\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/precision 0.90136\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            best/recall 0.47\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.5414\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.30499\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.90188\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.4703\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.03576\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.00776\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.02583\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.03477\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.00784\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.0253\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00134\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00134\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.00134\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 529 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmild-terrain-8\u001b[0m: \u001b[34mhttps://wandb.ai/obengdouglas/YOLOv5/runs/32t1fl0i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220211_061754-32t1fl0i/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Inference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09505bd5-c2fb-43ba-8b46-3c9977f983c3"
      },
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/Colab_Data/face-mask-detection/images/test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/drive/MyDrive/Colab_Data/face-mask-detection/images/test, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v6.0-248-gcb2ad9f torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss102_png.rf.a93f2ae33f1c8f64822395ac78b3630f.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 2/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss116_png.rf.a14c29577aba5bf6b28eff3e311f6e02.jpg: 640x640 6 with masks, Done. (0.034s)\n",
            "image 3/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss118_png.rf.a75a9a763ce8b6f2726861b6a5235431.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 4/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss119_png.rf.b69f06552d64715b7ace2e6a34b26d0f.jpg: 640x640 5 with masks, 2 without masks, Done. (0.034s)\n",
            "image 5/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss160_png.rf.93d2f63404620f526d66de7996c48980.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 6/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss161_png.rf.c87fa562e66adf2f523dbacaba183412.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 7/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss162_png.rf.33d20fe0de0bd1455c84a4a8e5baa8f0.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 8/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss168_png.rf.1dc7b4cf2dcfe26c356b32f590801160.jpg: 640x640 2 with masks, 2 without masks, Done. (0.034s)\n",
            "image 9/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss176_png.rf.5db10f4d217446d8efbd269d02c409dd.jpg: 640x640 9 with masks, 5 without masks, Done. (0.034s)\n",
            "image 10/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss197_png.rf.22df56dd24be53f1fedcc102efcd7fad.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 11/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss199_png.rf.6949ec34481a5f1297562affdac21b9d.jpg: 640x640 4 with masks, 1 without mask, Done. (0.034s)\n",
            "image 12/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss19_png.rf.f244f6d5bb4486cac312c47b34ed2bc0.jpg: 640x640 4 with masks, 2 without masks, Done. (0.034s)\n",
            "image 13/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss20_png.rf.37e98f13494101f58788c931876053d6.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 14/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss217_png.rf.ddc607800f5aedc74c5e17c9cc05bb1c.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 15/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss220_png.rf.92a9eed920d8937e0414dc01c34f723e.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 16/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss241_png.rf.4425b45afbd5c636961d4b6c98915672.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 17/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss255_png.rf.da0344e34c8fcee79a766e70e8477f22.jpg: 640x640 19 with masks, Done. (0.034s)\n",
            "image 18/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss26_png.rf.8698f59d70abfd43239ca4a2782b597c.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 19/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss273_png.rf.b3d91dc69868a01fe7eab114821fe274.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 20/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss284_png.rf.b33004e92992161bf6569a1b6cbfb318.jpg: 640x640 7 with masks, Done. (0.034s)\n",
            "image 21/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss28_png.rf.a44c248f5be9874d983a772c5d6aae12.jpg: 640x640 1 with mask, 1 without mask, Done. (0.034s)\n",
            "image 22/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss302_png.rf.8b3f0e92f2a6760b68f8409c6e654ef8.jpg: 640x640 3 with masks, Done. (0.034s)\n",
            "image 23/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss304_png.rf.40aac68e00e427c50f3f61892262ae63.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 24/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss305_png.rf.7f61c83d91fd46fc410974e31957c258.jpg: 640x640 8 with masks, 9 without masks, Done. (0.034s)\n",
            "image 25/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss311_png.rf.2879fff9220d305323160495c1f2b18c.jpg: 640x640 5 with masks, Done. (0.034s)\n",
            "image 26/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss320_png.rf.29b0129460866048e60f15ad804131ad.jpg: 640x640 4 with masks, 1 without mask, Done. (0.034s)\n",
            "image 27/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss341_png.rf.1279fa55948e495943cb432c59a31072.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 28/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss345_png.rf.b702c2d5bb5fd43d79ff1ee858b87c23.jpg: 640x640 1 with mask, 2 without masks, Done. (0.034s)\n",
            "image 29/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss349_png.rf.2b173e49724219eacc8f082f8658a65d.jpg: 640x640 3 with masks, Done. (0.034s)\n",
            "image 30/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss352_png.rf.6481430126e03061dfe92857cbc6bcae.jpg: 640x640 1 with mask, 1 without mask, Done. (0.034s)\n",
            "image 31/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss353_png.rf.a770bdbc75d3d796d1be0486f79df180.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 32/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss375_png.rf.9c7e49d84cf4fae1515afea4e1b046a6.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 33/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss386_png.rf.e70297b26adea5bd1a831a90f2b52ff8.jpg: 640x640 8 with masks, Done. (0.034s)\n",
            "image 34/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss389_png.rf.36fa9bc3c360d7e75d041e08eadbccf2.jpg: 640x640 10 with masks, Done. (0.034s)\n",
            "image 35/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss412_png.rf.0db312f343d72341ba772f87ea9069fc.jpg: 640x640 5 with masks, Done. (0.034s)\n",
            "image 36/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss41_png.rf.4b5b3c9d46f80a4d4ab84817005c44f9.jpg: 640x640 9 with masks, Done. (0.034s)\n",
            "image 37/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss420_png.rf.7ba67567475238d35cc0d90c4453035b.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 38/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss424_png.rf.01628e4a67e6e5e9db0f12ece300df82.jpg: 640x640 22 with masks, 5 without masks, Done. (0.034s)\n",
            "image 39/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss430_png.rf.f7b1e6ef08b0c749e7d6338716c3d2bc.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 40/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss43_png.rf.1052536a413f3f919801701ca72c1f19.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 41/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss444_png.rf.88c27ecf7ed3d97ebf1a8ebdb0587d93.jpg: 640x640 3 with masks, 2 without masks, Done. (0.034s)\n",
            "image 42/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss448_png.rf.c1ebc03bd4a9889dd60eddf51fcf69c9.jpg: 640x640 5 with masks, Done. (0.034s)\n",
            "image 43/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss458_png.rf.853273a6d3304a4d58955e9ee3698fa3.jpg: 640x640 2 with masks, 1 without mask, Done. (0.034s)\n",
            "image 44/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss463_png.rf.b73a1659419c8c3168051513d6f03ff7.jpg: 640x640 Done. (0.034s)\n",
            "image 45/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss469_png.rf.4d7b1498ac74c8df9a20337ebe064660.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 46/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss473_png.rf.730e72a82ece8a862742585b2e26c6af.jpg: 640x640 3 with masks, 1 without mask, Done. (0.034s)\n",
            "image 47/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss481_png.rf.5469e0fc2f5dd02e5fbf57a9fd1ec2b3.jpg: 640x640 6 with masks, Done. (0.034s)\n",
            "image 48/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss482_png.rf.be15a166298aab7c43b066613713efdb.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 49/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss485_png.rf.1ea3407e92ab05f675ebec3a470f28ef.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 50/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss499_png.rf.7f5a3d554e7b45bf951a83f29694fd7a.jpg: 640x640 1 with mask, 1 without mask, Done. (0.034s)\n",
            "image 51/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss500_png.rf.5fc2cc4d40db667a2748486c24bc3487.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 52/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss516_png.rf.2baa7109c154ae40b3c50d9d4e7c6c31.jpg: 640x640 7 with masks, Done. (0.034s)\n",
            "image 53/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss51_png.rf.6a3cba4254db8ae65521967e08981731.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 54/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss530_png.rf.fd7ed0ef6a0fb206d3dcd7a33761dd2f.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 55/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss548_png.rf.a417daa5855f130bbbce144fbf460b20.jpg: 640x640 2 with masks, 1 without mask, Done. (0.034s)\n",
            "image 56/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss558_png.rf.4083589c62246f098f6ab58bfa2792ce.jpg: 640x640 16 with masks, 4 without masks, Done. (0.034s)\n",
            "image 57/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss564_png.rf.ae902018a1a0e2056d83a98c6d04cd02.jpg: 640x640 19 with masks, 3 without masks, Done. (0.034s)\n",
            "image 58/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss577_png.rf.a821fb6febe3fe2515dd26bb1dc47c24.jpg: 640x640 11 with masks, 1 without mask, Done. (0.034s)\n",
            "image 59/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss589_png.rf.ef7cf4941d835bdee822fe0047418a57.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 60/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss607_png.rf.6d96732a44e50165a42ecdd78d232c45.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 61/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss619_png.rf.f88c0657647d52a0c582fa9bf7ff6c0d.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 62/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss623_png.rf.bf65875fc9f2cd7d4c7d3fb1ca6a4574.jpg: 640x640 21 with masks, 3 without masks, Done. (0.034s)\n",
            "image 63/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss635_png.rf.4800ab01c501b294ab0f23cf93b58373.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 64/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss63_png.rf.1dbb7c02ad6eb9e41005f290151342a9.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 65/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss642_png.rf.0b8d6b8cef2470eb93be1387c9c3623c.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 66/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss648_png.rf.5b0b9301cc3116ee39718da56651edb8.jpg: 640x640 3 with masks, Done. (0.034s)\n",
            "image 67/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss654_png.rf.fcb1c3e63dcc194032a1c241ed41b9b8.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 68/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss659_png.rf.c8317dbfe52bf624071c82c8963d7caa.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 69/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss669_png.rf.9702133b1052e74b0107c5293d38e72d.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 70/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss684_png.rf.422684f449298b965b3d53ed7cbad0db.jpg: 640x640 4 with masks, 2 without masks, Done. (0.034s)\n",
            "image 71/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss695_png.rf.6bab340b52272672ebdd3289e799784d.jpg: 640x640 21 with masks, 5 without masks, Done. (0.034s)\n",
            "image 72/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss715_png.rf.72fc526fbcbcf48e2ec3d7f390c88e79.jpg: 640x640 2 with masks, 1 without mask, Done. (0.034s)\n",
            "image 73/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss745_png.rf.860179aab8ef1b874e36267e06dcefbf.jpg: 640x640 2 with masks, Done. (0.034s)\n",
            "image 74/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss763_png.rf.03b3856d20edc4457ba85253c143e5ee.jpg: 640x640 4 with masks, Done. (0.034s)\n",
            "image 75/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss77_png.rf.98255b81d396ecd0b555e6c99d2d0009.jpg: 640x640 3 with masks, Done. (0.034s)\n",
            "image 76/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss780_png.rf.777b10b4f60a57a5e459e7fafd52df61.jpg: 640x640 4 with masks, Done. (0.034s)\n",
            "image 77/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss786_png.rf.b1d374f6269e787ce0eaf8af8f0d4d43.jpg: 640x640 4 with masks, Done. (0.034s)\n",
            "image 78/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss797_png.rf.821a5508b744478ae8739291b988344a.jpg: 640x640 7 with masks, Done. (0.034s)\n",
            "image 79/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss802_png.rf.d1808cd09bac774692a0d816783e65ea.jpg: 640x640 4 with masks, Done. (0.034s)\n",
            "image 80/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss815_png.rf.ea41e968f8aeb755d7bb3352d2415a3c.jpg: 640x640 Done. (0.034s)\n",
            "image 81/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss825_png.rf.8c7818743fa183ef058ad12539e5cfa9.jpg: 640x640 4 with masks, Done. (0.034s)\n",
            "image 82/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss852_png.rf.e1cabbbe320c3dfb266266af84e41851.jpg: 640x640 1 without mask, Done. (0.034s)\n",
            "image 83/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss88_png.rf.35e8cc79f8bc3c94ad0e182661bc4379.jpg: 640x640 1 with mask, Done. (0.034s)\n",
            "image 84/84 /content/drive/.shortcut-targets-by-id/1JrzNTOP9woECJL-FxjOqkf1slRlt6BHS/face-mask-detection/images/test/maksssksksss94_png.rf.74b6f46f1270c405d7498291c7d21724.jpg: 640x640 6 with masks, 2 without masks, Done. (0.034s)\n",
            "Speed: 0.8ms pre-process, 33.9ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVRSOhEvUdb5"
      },
      "source": [
        "# Evolve\n",
        "# !python train.py --img 640 --batch 64 --epochs 100 --data coco128.yaml --weights yolov5s.pt --cache --noautoanchor --evolve\n",
        "# !d=runs/train/evolve && cp evolve.* $d && zip -r evolve.zip $d && gsutil mv evolve.zip gs://bucket  # upload results (optional)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrpmDiOjLACy",
        "outputId": "61e2ffac-6cdb-4124-a35e-68d7a35c49a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-2.7.5.2-py3-none-any.whl (871 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 871 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.0 MB 36.5 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.73.0-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52 kB 853 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.17.4-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.9.2-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.19.5)\n",
            "Collecting markdown2\n",
            "  Downloading markdown2-2.4.2-py2.py3-none-any.whl (34 kB)\n",
            "Collecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.0.11)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (3.10.0.2)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 144 kB 40.7 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 271 kB 43.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.9 MB 31.6 MB/s \n",
            "\u001b[?25hCollecting starlette==0.17.1\n",
            "  Downloading starlette-0.17.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61 kB 419 kB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 856 kB 39.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.6 MB 25.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
            "Collecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.5.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58 kB 5.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=9336ba60df9cba662c7a150f90a576c69ebee84268c9684f49ec2bea6837cdd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=2ed5f735e262ecd5f99d96fc28c2fc4cf86cfc0ac35fcda5c8dfb2568c0d84c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, multidict, frozenlist, anyio, yarl, starlette, pynacl, pydantic, monotonic, h11, cryptography, bcrypt, backoff, asynctest, async-timeout, asgiref, aiosignal, uvicorn, python-multipart, pydub, pycryptodome, paramiko, markdown2, ffmpy, fastapi, analytics-python, aiohttp, gradio\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.5.0 asgiref-3.5.0 async-timeout-4.0.2 asynctest-0.13.0 backoff-1.10.0 bcrypt-3.2.0 cryptography-36.0.1 fastapi-0.73.0 ffmpy-0.3.0 frozenlist-1.3.0 gradio-2.7.5.2 h11-0.13.0 markdown2-2.4.2 monotonic-1.6 multidict-6.0.2 paramiko-2.9.2 pycryptodome-3.14.1 pydantic-1.9.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 sniffio-1.2.0 starlette-0.17.1 uvicorn-0.17.4 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "best = /content/yolov5/runs/train/exp/weights/best.pt\n",
        "def video_flip(video):\n",
        "    return video\n",
        "\n",
        "\n",
        "best.pt = gr.Interface(video_flip, gr.inputs.Video(source=\"webcam\"), \"playable_video\")\n",
        "\n",
        "best.pt.launch()"
      ],
      "metadata": {
        "id": "J87h_cfZLI5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:pass"
      ],
      "metadata": {
        "id": "ZXpmz5ysOCQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "9cbe24c6-4f8f-4e5c-8d02-5a1e1e7f5808"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-534b7a74019f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "metadata": {
        "id": "fFEig1wspPtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple sequential model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2c8EqYTdqLho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}